"""
ê¸ˆìœµìœ„ì›íšŒ ë¬¸ì„œ íŒŒì‹± ëª¨ë“ˆ
- HWP, HWPX, TXT íŒŒì¼ íŒŒì‹±
- JSON ë³€í™˜ ë° í’ˆì§ˆ ê´€ë¦¬
"""

import os
import json
import re
import pathlib
import shutil
import tempfile
import zipfile
from bs4 import BeautifulSoup
from datetime import datetime
from typing import List, Dict, Optional, Tuple, Any


def clean_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ ì •ë¦¬"""
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'[^\wê°€-í£ .,?!:;\\\-â–¡â– â—‹â—â–³â–²â–½â–¼â€»*â€¢â€“â€”()\\\[\\\]]', '', text)
    return text.strip()


def hwp2html(hwp_file_path: str, html_file_dir: str) -> None:
    """HWP íŒŒì¼ì„ HTMLë¡œ ë³€í™˜"""
    os.system(f'hwp5html --output "{html_file_dir}" "{hwp_file_path}"')


class DocumentParser:
    """ë¬¸ì„œ íŒŒì‹± í´ë˜ìŠ¤"""
    
    def __init__(self):
        pass
    
    def extract_from_txt(self, file_path: str) -> Optional[Tuple[str, str, str]]:
        """TXT íŒŒì¼ì—ì„œ ì§ˆì˜ìš”ì§€, íšŒë‹µ, ì´ìœ  ì¶”ì¶œ"""
        # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì œì™¸
        if 'NAL_1761' in file_path:
            print(f"âŒ ì œì™¸: {file_path} (ì‹ ì²­ì¸ ì² íšŒ)")
            return None

        with open(file_path, 'r', encoding='utf-8') as f:
            text = f.read()

        # íŒ¨í„´ ì •ì˜ (ë„ì–´ì“°ê¸°/ê°œí–‰ í—ˆìš©)
        patterns = {
            'question': [
                r'(ìš”ì²­\s*ëŒ€ìƒ\s*í–‰ìœ„)[\s:ï¼š]*([\\s\\S]*?)(?=(\n\s*(ì§ˆì˜\s*ìš”ì§€|íšŒë‹µ|íŒë‹¨|ì´ìœ |íŒë‹¨\s*ì´ìœ |íŒë‹¨ì´ìœ )|$))',
                r'(ì§ˆì˜\s*ìš”ì§€)[\s:ï¼š]*([\\s\\S]*?)(?=(\n\s*(ìš”ì²­\s*ëŒ€ìƒ\s*í–‰ìœ„|íšŒë‹µ|íŒë‹¨|ì´ìœ |íŒë‹¨\s*ì´ìœ |íŒë‹¨ì´ìœ )|$))'
            ],
            'answer': [
                r'(íšŒë‹µ|íŒë‹¨)[\s:ï¼š]*([\\s\\S]*?)(?=(\n\s*(ì´ìœ |íŒë‹¨\s*ì´ìœ |íŒë‹¨ì´ìœ )|$))'
            ],
            'reason': [
                r'(ì´ìœ |íŒë‹¨\s*ì´ìœ |íŒë‹¨ì´ìœ )[\s:ï¼š]*([\\s\\S]*?)(?=$)'
            ]
        }

        def extract(patterns):
            for pat in patterns:
                m = re.search(pat, text, re.IGNORECASE)
                if m:
                    return m.group(2).strip()
            return ""

        question = extract(patterns['question'])
        answer = extract(patterns['answer'])
        reason = extract(patterns['reason'])

        # "ìš”ì²­ì„ ë°˜ë ¤í•©ë‹ˆë‹¤" í•„í„°ë§
        if 'ìš”ì²­ì„ ë°˜ë ¤í•©ë‹ˆë‹¤' in answer or 'ìš”ì²­ì„ ë°˜ë ¤í•©ë‹ˆë‹¤' in reason:
            print(f"âŒ ì œì™¸: {file_path} (ìš”ì²­ì„ ë°˜ë ¤í•©ë‹ˆë‹¤ í¬í•¨)")
            return None

        return clean_text(question), clean_text(answer), clean_text(reason)

    def extract_from_hwp(self, file_path: str) -> Optional[Tuple[str, str, str]]:
        """HWP íŒŒì¼ì—ì„œ ì§ˆì˜ìš”ì§€, íšŒë‹µ, ì´ìœ  ì¶”ì¶œ"""
        # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì²˜ë¦¬
        if 'LAW_3880' in file_path:
            hwp_file_dir = os.path.dirname(file_path)
            hwp_file_name = os.path.basename(file_path)
            html_file_dir = os.path.join(hwp_file_dir, hwp_file_name.split('.')[0])
            html_file_path = os.path.join(html_file_dir, 'index.xhtml')
            hwp2html(file_path, html_file_dir)
            page = open(html_file_path, 'rt', encoding='utf-8').read()
            page = BeautifulSoup(page, 'html.parser')
            shutil.rmtree(html_file_dir)
            text = page.get_text(separator='\n')
            q_start = text.find('ì§ˆì˜ ìš”ì§€')
            a_start = text.find('íšŒë‹µ')
            r_start = text.find('ì´ìœ ')
            question = text[q_start+len('ì§ˆì˜ ìš”ì§€'):a_start].strip() if q_start != -1 and a_start != -1 else ""
            answer = text[a_start+len('íšŒë‹µ'):r_start].strip() if a_start != -1 and r_start != -1 else ""
            reason = text[r_start+len('ì´ìœ '):].strip() if r_start != -1 else ""
            if 'ìš”ì²­ì„ ë°˜ë ¤í•©ë‹ˆë‹¤' in answer or 'ìš”ì²­ì„ ë°˜ë ¤í•©ë‹ˆë‹¤' in reason:
                print(f"âŒ ì œì™¸: {file_path} (ìš”ì²­ì„ ë°˜ë ¤í•©ë‹ˆë‹¤ í¬í•¨)")
                return None
            return clean_text(question), clean_text(answer), clean_text(reason)
            
        # NAL_1761 ì˜ˆì™¸ ì²˜ë¦¬
        if 'NAL_1761' in file_path:
            print(f"âŒ ì œì™¸: {file_path} (ì‹ ì²­ì¸ ì² íšŒ)")
            return None

        hwp_file_dir = os.path.dirname(file_path)
        hwp_file_name = os.path.basename(file_path)
        html_file_dir = os.path.join(hwp_file_dir, hwp_file_name.split('.')[0])
        html_file_path = os.path.join(html_file_dir, 'index.xhtml')
        
        hwp2html(file_path, html_file_dir)
        
        page = open(html_file_path, 'rt', encoding='utf-8').read()
        page = BeautifulSoup(page, 'html.parser')
        shutil.rmtree(html_file_dir)

        tag_list = page.find_all('td')
        question, answer, reason = "", "", ""

        # íŒ¨í„´: ë„ì–´ì“°ê¸°/ê°œí–‰ í—ˆìš©
        question_patterns = ['ì§ˆì˜ìš”ì§€', 'ì§ˆì˜ ìš”ì§€', 'ìš”ì²­ëŒ€ìƒí–‰ìœ„', 'ìš”ì²­ ëŒ€ìƒ í–‰ìœ„']
        answer_patterns = ['íšŒë‹µ', 'íŒë‹¨']
        reason_patterns = ['ì´ìœ ', 'íŒë‹¨ì´ìœ ', 'íŒë‹¨ ì´ìœ ']

        for idx, tag in enumerate(tag_list):
            tag_text = tag.get_text().replace(" ", "").replace("\n", "")
            # ì§ˆì˜ìš”ì§€: íŒ¨í„´ ì¤‘ í•˜ë‚˜ê°€ í¬í•¨ëœ ì…€(ì œëª©)ì´ë©´
            if any(pat.replace(" ", "") in tag_text for pat in question_patterns) and len(tag_text) < 12:
                question = tag_list[idx+1].get_text()
            # íšŒë‹µ
            if any(pat in tag_text for pat in answer_patterns) and len(tag_text) < 10:
                answer = tag_list[idx+1].get_text()
            # ì´ìœ 
            if any(pat in tag_text for pat in reason_patterns) and len(tag_text) < 10:
                reason = tag_list[idx+1].get_text()

        # "ìš”ì²­ì„ ë°˜ë ¤í•©ë‹ˆë‹¤" í•„í„°ë§
        if 'ìš”ì²­ì„ ë°˜ë ¤í•©ë‹ˆë‹¤' in answer or 'ìš”ì²­ì„ ë°˜ë ¤í•©ë‹ˆë‹¤' in reason:
            print(f"âŒ ì œì™¸: {file_path} (ìš”ì²­ì„ ë°˜ë ¤í•©ë‹ˆë‹¤ í¬í•¨)")
            return None

        return clean_text(question), clean_text(answer), clean_text(reason)

    def extract_from_hwpx(self, file_path: str) -> Optional[Tuple[str, str, str]]:
        """HWPX íŒŒì¼ì—ì„œ ì§ˆì˜ìš”ì§€, íšŒë‹µ, ì´ìœ  ì¶”ì¶œ"""
        # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì œì™¸
        if 'LAW_3134' in file_path or 'NAL_2258' in file_path:
            print(f"âŒ ì œì™¸: {file_path} (íŠ¹ìˆ˜ ì¼€ì´ìŠ¤, ë‚´ìš© ë¬´ì‹œ)")
            return None

        # NAL_1761 ì˜ˆì™¸ ì²˜ë¦¬
        if 'NAL_1761' in file_path:
            print(f"âŒ ì œì™¸: {file_path} (ì‹ ì²­ì¸ ì² íšŒ)")
            return None

        question, answer, reason = "", "", ""
        
        with tempfile.TemporaryDirectory() as temp_dir:
            try:
                # HWPX íŒŒì¼ì„ ZIPìœ¼ë¡œ ì••ì¶•í•´ì œ
                with zipfile.ZipFile(file_path, 'r') as zip_ref:
                    zip_ref.extractall(temp_dir)
                
                # section XML íŒŒì¼ë“¤ ì°¾ê¸°
                contents_dir = os.path.join(temp_dir, 'Contents')
                section_files = [f for f in os.listdir(contents_dir) if f.startswith('section') and f.endswith('.xml')]
                
                all_text = ""
                cell_list = []

                for section_file in section_files:
                    section_path = os.path.join(contents_dir, section_file)
                    
                    with open(section_path, 'r', encoding='utf-8') as f:
                        xml_content = f.read()
                    
                    # BeautifulSoupìœ¼ë¡œ XML íŒŒì‹±
                    soup = BeautifulSoup(xml_content, 'lxml-xml')
                    
                    # í‘œ ë°ì´í„° ì¶”ì¶œ
                    tables = soup.find_all("hp:tbl")
                    for table in tables:
                        rows = table.find_all("hp:tr")
                        for row in rows:
                            cells = row.find_all("hp:tc")
                            for cell in cells:
                                cell_text = cell.get_text(strip=True)
                                if cell_text:
                                    cell_list.append(cell_text)
                                    all_text += cell_text + " "
                    
                    # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    text_elements = soup.find_all(['hp:t', 'hp:tc'])
                    for elem in text_elements:
                        text = elem.get_text(strip=True)
                        if text:
                            all_text += text + " "
                
                # ì…€ ê¸°ë°˜ section ì¶”ì¶œ
                for idx, cell in enumerate(cell_list):
                    cell_nospace = cell.replace(" ", "")
                    # ì§ˆì˜ìš”ì§€: 'ì§ˆì˜'ê°€ í¬í•¨ëœ ì…€(ì œëª©)ì´ë©´ ë¬´ì¡°ê±´
                    if 'ì§ˆì˜' in cell_nospace and len(cell_nospace) < 12 and idx+1 < len(cell_list):
                        question = cell_list[idx+1]
                    # íšŒë‹µ
                    if any(pat in cell_nospace for pat in ['íšŒë‹µ', 'íŒë‹¨']) and len(cell_nospace) < 10 and idx+1 < len(cell_list):
                        answer = cell_list[idx+1]
                    # ì´ìœ 
                    if any(pat in cell_nospace for pat in ['ì´ìœ ', 'íŒë‹¨ì´ìœ ', 'íŒë‹¨ì´ìœ ']) and len(cell_nospace) < 10 and idx+1 < len(cell_list):
                        reason = cell_list[idx+1]

                # ë§Œì•½ ì…€ ê¸°ë°˜ ì¶”ì¶œì´ ëª¨ë‘ ì‹¤íŒ¨í•˜ë©´ ê¸°ì¡´ íŒ¨í„´ë„ ì‹œë„
                if not question and not answer and not reason:
                    text_parts = all_text.split()
                    text_joined = " ".join(text_parts)
                    patterns = {
                        'question': [
                            r'(ì§ˆì˜ìš”ì§€|ìš”ì²­\s*ëŒ€ìƒ\s*í–‰ìœ„)[\s:ï¼š]*([\\s\\S]*?)(?=(íšŒë‹µ|íŒë‹¨|ì´ìœ |íŒë‹¨\s*ì´ìœ |íŒë‹¨ì´ìœ |$))'
                        ],
                        'answer': [
                            r'(íšŒë‹µ|íŒë‹¨)[\s:ï¼š]*([\\s\\S]*?)(?=(ì´ìœ |íŒë‹¨\s*ì´ìœ |íŒë‹¨ì´ìœ |$))'
                        ],
                        'reason': [
                            r'(ì´ìœ |íŒë‹¨\s*ì´ìœ |íŒë‹¨ì´ìœ )[\s:ï¼š]*([\\s\\S]*?)(?=$)'
                        ]
                    }
                    def extract(patterns):
                        for pat in patterns:
                            m = re.search(pat, text_joined, re.IGNORECASE)
                            if m:
                                return m.group(2).strip()
                        return ""
                    question = extract(patterns['question'])
                    answer = extract(patterns['answer'])
                    reason = extract(patterns['reason'])
                
                # íŒ¨í„´ ë§¤ì¹­ì´ ì‹¤íŒ¨í•œ ê²½ìš° ê°„ë‹¨í•œ ë¶„í•  ì‹œë„
                if not question and not answer and not reason:
                    text_length = len(all_text)
                    if text_length > 0:
                        third = text_length // 3
                        question = all_text[:third].strip()
                        answer = all_text[third:third*2].strip()
                        reason = all_text[third*2:].strip()
            
            except Exception as e:
                print(f"HWPX íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                question = all_text if 'all_text' in locals() else ""
        
        # "ìš”ì²­ì„ ë°˜ë ¤í•©ë‹ˆë‹¤" í•„í„°ë§
        if 'ìš”ì²­ì„ ë°˜ë ¤í•©ë‹ˆë‹¤' in answer or 'ìš”ì²­ì„ ë°˜ë ¤í•©ë‹ˆë‹¤' in reason:
            print(f"âŒ ì œì™¸: {file_path} (ìš”ì²­ì„ ë°˜ë ¤í•©ë‹ˆë‹¤ í¬í•¨)")
            return None

        return clean_text(question), clean_text(answer), clean_text(reason)

    def make_json_from_dir(self, target_dir: str, output_json: str) -> Dict[str, Any]:
        """ë””ë ‰í† ë¦¬ ë‚´ ë¬¸ì„œë“¤ì„ JSONìœ¼ë¡œ ë³€í™˜"""
        data = []
        stats = {
            "total_files": 0,
            "processed_files": 0,
            "excluded_files": 0,
            "errors": []
        }
        
        if not os.path.exists(target_dir):
            print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {target_dir}")
            return {"data": data, "stats": stats}
        
        files = [f for f in os.listdir(target_dir) if os.path.isfile(os.path.join(target_dir, f))]
        stats["total_files"] = len(files)
        
        for file_name in files:
            file_path = os.path.join(target_dir, file_name)
            ext = pathlib.Path(file_path).suffix.lower()
            
            try:
                if ext == '.txt':
                    result = self.extract_from_txt(file_path)
                elif ext == '.hwp':
                    result = self.extract_from_hwp(file_path)
                elif ext == '.hwpx':
                    result = self.extract_from_hwpx(file_path)
                else:
                    print(f"âš ï¸  ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_name}")
                    continue

                # None ë°˜í™˜ì‹œ ì œì™¸
                if result is None or all(x is None for x in result):
                    print(f"ğŸš« ì œì™¸: {file_name} (í•„í„° ì¡°ê±´ ë¶ˆì¶©ì¡±)")
                    stats["excluded_files"] += 1
                    continue

                question, answer, reason = result
                
                doc_id = os.path.splitext(file_name)[0]
                title = question if question else doc_id
                
                sections = []
                if question:
                    sections.append({"type": "ì§ˆì˜ìš”ì§€", "text": question})
                if answer:
                    sections.append({"type": "íšŒë‹µ", "text": answer})
                if reason:
                    sections.append({"type": "ì´ìœ ", "text": reason})
                
                item = {
                    "doc_id": doc_id,
                    "title": title,
                    "sections": sections,
                    "source": file_name,
                    "law_refs": [],
                    "tokens": len(question.split()) + len(answer.split()) + len(reason.split()),
                    "created_at": datetime.now().strftime("%Y-%m-%d"),
                    "quality_score": None,
                    "comments": [],
                    "status": "ë¯¸ê²€í† "
                }
                
                data.append(item)
                stats["processed_files"] += 1
                print(f"âœ… Success: {file_name}")
                
            except Exception as e:
                error_msg = f"âŒ Error: {file_name} : {e}"
                print(error_msg)
                stats["errors"].append(error_msg)
        
        # JSON íŒŒì¼ ì €ì¥
        os.makedirs(os.path.dirname(output_json), exist_ok=True)
        with open(output_json, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ‰ ì™„ë£Œ! {len(data)}ê°œ ë¬¸ì„œê°€ {output_json}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return {"data": data, "stats": stats}

    def update_document_quality(self, doc_id: str, quality_score: int, comments: List[str], 
                              data_file: str) -> bool:
        """ë¬¸ì„œ í’ˆì§ˆ ì •ë³´ ì—…ë°ì´íŠ¸"""
        try:
            with open(data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            for item in data:
                if item["doc_id"] == doc_id:
                    item["quality_score"] = quality_score
                    item["comments"] = comments
                    item["status"] = "ê²€í† ì™„ë£Œ" if quality_score >= 3 else "ìˆ˜ì •í•„ìš”"
                    break
            else:
                return False
            
            with open(data_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            return True
            
        except Exception as e:
            print(f"âŒ í’ˆì§ˆ ì •ë³´ ì—…ë°ì´íŠ¸ ì—ëŸ¬: {e}")
            return False