"""
Streamlitì„ ì´ìš©í•œ ê¸ˆìœµê°ë…ì› ì œì¬/ê²½ì˜ìœ ì˜ì‚¬í•­ RAG ì‹œìŠ¤í…œ ì›¹ ì¸í„°í˜ì´ìŠ¤
- ë²¡í„° ì €ì¥ì†Œ ê¸°ë°˜ RAG ì‹œìŠ¤í…œ ì—°ê²°
- ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ì œê³µ
- ê²€ìƒ‰ ê²°ê³¼ ì‹œê°í™”
"""

import os
import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import json
import time
from typing import Dict, List, Any, Union
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# RAG ì‹œìŠ¤í…œ ê°€ì ¸ì˜¤ê¸°
from rag_system import FSSRagSystem

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê¸ˆìœµê°ë…ì› ì œì¬ì •ë³´ ì±—ë´‡",
    page_icon="ğŸ’¼",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ìŠ¤íƒ€ì¼ ì¶”ê°€
st.markdown("""
<style>
.main-header {
    font-size: 2.5rem;
    color: #1E3A8A;
}
.sub-header {
    font-size: 1.5rem;
    color: #3B82F6;
}
.source-card {
    background-color: #F3F4F6;
    border-left: 4px solid #3B82F6;
    padding: 1rem;
    margin-bottom: 1rem;
    border-radius: 0.5rem;
}
.source-title {
    font-weight: bold;
    color: #1E3A8A;
}
.source-content {
    color: #1F2937;  /* ì–´ë‘ìš´ íšŒìƒ‰ */
    margin-top: 0.5rem;
}
.source-metadata {
    color: #374151;  /* ì¤‘ê°„ í†¤ì˜ íšŒìƒ‰ */
    margin: 0.25rem 0;
}
.chat-message {
    padding: 1.5rem;
    border-radius: 0.5rem;
    margin-bottom: 1rem;
    display: flex;
    font-size: 1.1rem;
    line-height: 1.5;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
}
.user-message {
    background-color: #E0F2FE;
    margin-left: 2rem;
    border-left: 4px solid #0EA5E9;
    font-weight: 500;
}
.bot-message {
    background-color: #F0FDF4;
    margin-right: 2rem;
    border-left: 4px solid #10B981;
    font-weight: 500;
}
.message-content {
    font-size: 1.1rem;
    color: #111827;
}
.message-role {
    font-weight: bold;
    margin-right: 0.5rem;
    color: #1F2937;
}
.system-message {
    background-color: #FEF3C7;
    margin: 1rem 0;
    padding: 0.75rem;
    border-radius: 0.5rem;
    border-left: 4px solid #F59E0B;
    font-weight: 500;
}
</style>
""", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "rag_system" not in st.session_state:
    st.session_state.rag_system = None
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "vector_db_path" not in st.session_state:
    st.session_state.vector_db_path = "data/vector_db/fss_sanctions"  # './' ì œê±°
if "embed_model" not in st.session_state:
    st.session_state.embed_model = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
if "openai_api_key" not in st.session_state:
    st.session_state.openai_api_key = os.getenv("OPENAI_API_KEY", "")
if "use_openai_embeddings" not in st.session_state:
    st.session_state.use_openai_embeddings = True  # ê¸°ë³¸ê°’ì„ Trueë¡œ ë³€ê²½
if "llm_model" not in st.session_state:
    st.session_state.llm_model = "gpt-3.5-turbo"  # OpenAI ëª¨ë¸ë¡œ ë³€ê²½
if "top_k" not in st.session_state:
    st.session_state.top_k = 5
if "use_anthropic" not in st.session_state:
    st.session_state.use_anthropic = False  # ê¸°ë³¸ê°’ì„ Falseë¡œ ì„¤ì •
if "use_faiss" not in st.session_state:
    st.session_state.use_faiss = True  # FAISS ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’ True)
if "use_openai_llm" not in st.session_state:
    st.session_state.use_openai_llm = True  # OpenAI LLM ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’ True)
if "vector_store_loaded" not in st.session_state:
    st.session_state.vector_store_loaded = False
if "vector_store_created" not in st.session_state:
    st.session_state.vector_store_created = False

def load_vector_store():
    """ì €ì¥ëœ ë²¡í„° ì €ì¥ì†Œë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    if not st.session_state.vector_store_loaded:
        # API í‚¤ í™•ì¸
        if not st.session_state.openai_api_key:
            st.error("âš ï¸ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return False
            
        with st.spinner("ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì¤‘..."):
            try:
                # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œ ì„¤ì •
                current_dir = os.path.dirname(os.path.abspath(__file__))
                
                # í´ë¼ìš°ë“œ í™˜ê²½ í™•ì¸ ë° ê²½ë¡œ ì„¤ì •
                is_cloud = current_dir.startswith('/mount/src')
                if is_cloud:
                    base_dir = '/mount/src/rag_eight'
                else:
                    base_dir = current_dir
                
                # ë²¡í„° ì €ì¥ì†Œ ê²½ë¡œ ì„¤ì •
                vector_store_path = os.path.join(base_dir, st.session_state.vector_db_path)
                
                # ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
                # st.write("ë””ë²„ê·¸ ì •ë³´:")
                # st.write(f"ì‹¤í–‰ í™˜ê²½: {'í´ë¼ìš°ë“œ' if is_cloud else 'ë¡œì»¬'}")
                # st.write(f"í˜„ì¬ ë””ë ‰í† ë¦¬: {current_dir}")
                # st.write(f"ê¸°ì¤€ ë””ë ‰í† ë¦¬: {base_dir}")
                # st.write(f"ë²¡í„° ì €ì¥ì†Œ ê²½ë¡œ: {vector_store_path}")
                # st.write(f"ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(vector_store_path)}")
                
                # ë²¡í„° ì €ì¥ì†Œ ì •ë³´ íŒŒì¼ í™•ì¸
                info_path = os.path.join(vector_store_path, "vector_store_info.json")
                if not os.path.exists(info_path):
                    st.error(f"âŒ ë²¡í„° ì €ì¥ì†Œ ì •ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {info_path}")
                    st.info("ë²¡í„° ì €ì¥ì†Œë¥¼ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”. (run_pipeline.py ì‹¤í–‰)")
                    return False
                
                # ë²¡í„° ì €ì¥ì†Œ ì •ë³´ ë¡œë“œ
                with open(info_path, 'r', encoding='utf-8') as f:
                    info = json.load(f)
                    st.write("ë²¡í„° ì €ì¥ì†Œ ì •ë³´:")
                    st.write(info)
                
                # OpenAI API í‚¤ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
                os.environ["OPENAI_API_KEY"] = st.session_state.openai_api_key
                
                # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ)
                rag_system = FSSRagSystem(
                    vector_db_path=vector_store_path,
                    embed_model_name=info.get('embed_model', st.session_state.embed_model),
                    use_openai_embeddings=info.get('use_openai', True),
                    use_anthropic=False,
                    use_faiss=info.get('vector_store_type', 'FAISS') == 'FAISS'
                )
                
                if rag_system.vector_store:
                    st.session_state.rag_system = rag_system
                    st.session_state.vector_store_loaded = True
                    st.success("âœ… ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì™„ë£Œ!")
                    return True
                else:
                    st.error("âŒ ë²¡í„° ì €ì¥ì†Œ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    return False
                    
            except Exception as e:
                st.error(f"âŒ ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                return False
    return True

# ì‚¬ì´ë“œë°”ì— RAG ì‹œìŠ¤í…œ ì„¤ì •
with st.sidebar:
    # st.markdown("### API í‚¤ ì„¤ì •")
    # api_key = st.text_input("OpenAI API í‚¤", value=st.session_state.openai_api_key, type="password")
    
    if api_key:
        # API í‚¤ í˜•ì‹ ê²€ì¦
        if not api_key.startswith('sk-') or len(api_key) < 40:
            st.error("âŒ ì˜¬ë°”ë¥´ì§€ ì•Šì€ OpenAI API í‚¤ í˜•ì‹ì…ë‹ˆë‹¤. 'sk-'ë¡œ ì‹œì‘í•˜ëŠ” ì˜¬ë°”ë¥¸ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            st.session_state.openai_api_key = api_key
            os.environ["OPENAI_API_KEY"] = api_key
            if st.session_state.openai_api_key != api_key:
                st.session_state.vector_store_loaded = False
            st.success("âœ… OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    if not st.session_state.openai_api_key:
        st.error("âš ï¸ OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤!")
        st.info("OpenAI API í‚¤ëŠ” https://platform.openai.com/account/api-keys ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    st.markdown("### ì‹œìŠ¤í…œ ì„¤ì •")
    
    # ë²¡í„° ì €ì¥ì†Œ ì„ íƒ
    vector_db_options = {
        "ì œì¬ ì •ë³´": "data/vector_db/fss_sanctions",
        "ê²½ì˜ìœ ì˜ì‚¬í•­": "data/vector_db/fss_management",
    }
    
    vector_db = st.selectbox(
        "ë²¡í„° ì €ì¥ì†Œ ì„ íƒ",
        options=list(vector_db_options.keys()),
        index=0,
        key="vector_db_selector"
    )
    
    # ë²¡í„° ì €ì¥ì†Œ ê²½ë¡œê°€ ë³€ê²½ëœ ê²½ìš° ì¬ë¡œë“œ í•„ìš”
    if st.session_state.vector_db_path != vector_db_options[vector_db]:
        st.session_state.vector_db_path = vector_db_options[vector_db]
        st.session_state.vector_store_loaded = False
    
    # ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ë²„íŠ¼
    if not st.session_state.vector_store_loaded:
        if st.button("ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ", type="primary"):
            if load_vector_store():
                st.success("âœ… ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì™„ë£Œ")
    else:
        st.success("âœ… ë²¡í„° ì €ì¥ì†Œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤")
    
    st.markdown("---")
    
    # LLM ì„ íƒ - Anthropic API ë˜ëŠ” OpenAI API
    st.markdown("### LLM ì„¤ì •")

    llm_provider = st.radio(
        "LLM ì œê³µì",
        ["OpenAI", "Anthropic"],
        index=0 if not st.session_state.use_anthropic else 1
    )

    st.session_state.use_anthropic = (llm_provider == "Anthropic")
    st.session_state.use_openai_llm = (llm_provider == "OpenAI")

    # OpenAI ëª¨ë¸ ì„ íƒ
    if st.session_state.use_openai_llm:
        openai_models = {
            "GPT-3.5 Turbo": "gpt-3.5-turbo",
            "GPT-4 Turbo": "gpt-4-turbo",
            "GPT-4o": "gpt-4o",
        }
        
        openai_model = st.selectbox(
            "OpenAI ëª¨ë¸",
            options=list(openai_models.keys()),
            index=0,
        )
        
        st.session_state.llm_model = openai_models[openai_model]
        
        # OpenAI API í‚¤ í™•ì¸
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if openai_api_key:
            st.success("âœ… OpenAI API í‚¤ê°€ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.error("âŒ í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # Anthropic API í‚¤ í™•ì¸ ë° í‘œì‹œ
    elif st.session_state.use_anthropic:
        anthropic_api_key = os.getenv("ANTHROPIC_APIKEY")
        if anthropic_api_key:
            st.success("âœ… Anthropic API í‚¤ê°€ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.error("âŒ í™˜ê²½ ë³€ìˆ˜ ANTHROPIC_APIKEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜
    # top_k = st.slider("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜", min_value=1, max_value=10, value=5)
    # st.session_state.top_k = top_k
    
    # LLM ì´ˆê¸°í™” ë²„íŠ¼
    if st.session_state.vector_store_loaded:
        if st.button("LLM ì´ˆê¸°í™”", type="primary"):
            with st.spinner("LLM ì´ˆê¸°í™” ì¤‘..."):
                try:
                    if st.session_state.use_anthropic:
                        anthropic_api_key = os.getenv("ANTHROPIC_APIKEY")
                        if not anthropic_api_key:
                            st.error("í™˜ê²½ ë³€ìˆ˜ ANTHROPIC_APIKEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            # ê¸°ì¡´ RAG ì‹œìŠ¤í…œì— LLM ì´ˆê¸°í™”
                            st.session_state.rag_system.use_anthropic = True
                            st.session_state.rag_system.anthropic_api_key = anthropic_api_key
                            st.session_state.rag_system.use_openai_llm = False
                            st.session_state.rag_system.use_faiss = st.session_state.use_faiss
                            st.session_state.rag_system.initialize_llm()
                            if st.session_state.rag_system.llm:
                                st.success("Anthropic Claude APIë¡œ LLM ì´ˆê¸°í™” ì™„ë£Œ!")
                            else:
                                st.error("LLM ì´ˆê¸°í™” ì‹¤íŒ¨. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    else:
                        # OpenAI API ì‚¬ìš©
                        openai_api_key = os.getenv("OPENAI_API_KEY")
                        if not openai_api_key:
                            st.error("í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            # ê¸°ì¡´ RAG ì‹œìŠ¤í…œì— LLM ì´ˆê¸°í™”
                            st.session_state.rag_system.use_anthropic = False
                            st.session_state.rag_system.use_openai_llm = True
                            st.session_state.rag_system.llm_model_name = st.session_state.llm_model
                            st.session_state.rag_system.use_faiss = st.session_state.use_faiss
                            st.session_state.rag_system.initialize_llm()
                            if st.session_state.rag_system.llm:
                                st.success(f"OpenAI {st.session_state.llm_model}ë¡œ LLM ì´ˆê¸°í™” ì™„ë£Œ!")
                            else:
                                st.error("LLM ì´ˆê¸°í™” ì‹¤íŒ¨. API í‚¤ë¥¼ í™•ì¸í•˜ê³  ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                except Exception as e:
                    st.error(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

    st.markdown("---")
    
    # ë¹ ë¥¸ ì§ˆë¬¸ ì˜ˆì‹œ
    st.markdown("### ì§ˆë¬¸ ì˜ˆì‹œ")
    example_questions = [
        "ìµœê·¼ 1ë…„ê°„ ì œì¬ë°›ì€ ì€í–‰ ì•Œë ¤ì¤˜",
        "ì‹ ìš©ì •ë³´ë²• ìœ„ë°˜ ì‚¬ë¡€ ìˆì–´?",
        "ì£¼ì˜ ì¡°ì¹˜ ë°›ì€ ê¸ˆìœµì‚¬ ì¤‘ ë‚´ë¶€í†µì œ ë¬¸ì œì˜€ë˜ ê²½ìš°?",
        "ê³¼ì§•ê¸ˆ ë¶€ê³¼ëœ ë³´í—˜ì‚¬ ì•Œë ¤ì¤˜",
        "ì „ìê¸ˆìœµ ê´€ë ¨ ê²½ì˜ìœ ì˜ì‚¬í•­ì€?"
    ]
    
    # ì˜ˆì‹œ ì§ˆë¬¸ì„ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜
    def set_example_question(question):
        # ë™ì¼í•œ ì§ˆë¬¸ì´ ì´ë¯¸ ë§ˆì§€ë§‰ìœ¼ë¡œ ì…ë ¥ëœ ê²½ìš° ì¤‘ë³µ ë°©ì§€
        if st.session_state.chat_history and len(st.session_state.chat_history) > 0:
            last_user_msg = None
            for msg in reversed(st.session_state.chat_history):
                if msg["role"] == "user":
                    last_user_msg = msg["content"]
                    break
            
            if last_user_msg == question:
                # ì´ë¯¸ ë™ì¼í•œ ì§ˆë¬¸ì´ ì¡´ì¬í•˜ë©´ ë‹¤ì‹œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
                return
        
        st.session_state.chat_input = question
        st.rerun()
    
    for q in example_questions:
        if st.sidebar.button(q):
            set_example_question(q)

# ë©”ì¸ í™”ë©´
st.markdown('<h1 class="main-header">ê¸ˆìœµê°ë…ì› ì œì¬ì •ë³´ ì±—ë´‡</h1>', unsafe_allow_html=True)
st.markdown('<h2 class="sub-header">ê¸ˆìœµ ì œì¬ ë° ê²½ì˜ìœ ì˜ì‚¬í•­ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ</h2>', unsafe_allow_html=True)

# ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
system_status_shown = False
if not st.session_state.vector_store_loaded:
    st.markdown('<div class="system-message">âš ï¸ ì‚¬ì´ë“œë°”ì—ì„œ ë²¡í„° ì €ì¥ì†Œë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”.</div>', unsafe_allow_html=True)
    system_status_shown = True
elif st.session_state.rag_system and not st.session_state.rag_system.llm:
    st.markdown('<div class="system-message">âš ï¸ ì‚¬ì´ë“œë°”ì—ì„œ LLMì„ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.</div>', unsafe_allow_html=True)
    system_status_shown = True

# ë²¡í„° ì €ì¥ì†Œ ìë™ ë¡œë“œ ì‹œë„ëŠ” ì œê±° (ì¤‘ë³µ ë©”ì‹œì§€ ë°©ì§€)

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for i, message in enumerate(st.session_state.chat_history):
    if message["role"] == "user":
        with st.container():
            st.markdown(f'<div class="chat-message user-message"><span class="message-role">ğŸ§‘â€ğŸ’¼</span><span class="message-content">{message["content"]}</span></div>', unsafe_allow_html=True)
    else:
        with st.container():
            st.markdown(f'<div class="chat-message bot-message"><span class="message-role">ğŸ¤–</span><span class="message-content">{message["content"]}</span></div>', unsafe_allow_html=True)
            
            if "sources" in message and message["sources"]:
                with st.expander("ì°¸ê³  ë¬¸ì„œ ë³´ê¸°"):
                    for j, source in enumerate(message["sources"][:3]):
                        metadata = source.get("metadata", {})
                        
                        # DB íƒ€ì…ì— ë”°ë¼ ë‚ ì§œì™€ ìœ í˜•ì„ ê²°ì •í•©ë‹ˆë‹¤.
                        date_to_display = metadata.get('date', metadata.get('sanction_date', metadata.get('disclosure_date', 'N/A')))
                        
                        if 'doc_type' in metadata:
                            type_to_display = metadata.get('doc_type', 'N/A')
                        elif 'sanction_type' in metadata:
                            type_to_display = metadata.get('sanction_type', 'N/A')
                        elif 'management_type' in metadata:
                            type_to_display = metadata.get('management_type', 'N/A') 
                        else:
                            type_to_display = 'N/A'

                        st.markdown(f"""
                        <div class="source-card">
                            <p class="source-title">ì¶œì²˜ #{j+1}</p>
                            <p class="source-metadata"><strong>ê¸°ê´€:</strong> {metadata.get('institution', 'N/A')}</p>
                            <p class="source-metadata"><strong>ë‚ ì§œ:</strong> {date_to_display}</p>
                            <p class="source-metadata"><strong>ìœ í˜•:</strong> {type_to_display}</p>
                            <div class="source-content">{source.get('content', '')[:300]}...</div>
                        </div>
                        """, unsafe_allow_html=True)

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...", key="chat_input")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    
    # ë²¡í„° ì €ì¥ì†Œì™€ LLM ìƒíƒœ í™•ì¸
    if not st.session_state.vector_store_loaded:
        error_msg = "ë²¡í„° ì €ì¥ì†Œê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ 'ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ' ë²„íŠ¼ì„ í´ë¦­í•´ì£¼ì„¸ìš”."
        st.session_state.chat_history.append({
            "role": "assistant", 
            "content": error_msg,
            "sources": []
        })
        st.error(error_msg)
        st.rerun()
    elif st.session_state.rag_system and not st.session_state.rag_system.llm:
        error_msg = "LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ 'LLM ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•´ì£¼ì„¸ìš”."
        st.session_state.chat_history.append({
            "role": "assistant", 
            "content": error_msg,
            "sources": []
        })
        st.error(error_msg)
        st.rerun()
    else:
        # ì‹œìŠ¤í…œ ì‘ë‹µ ìƒì„±
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                response = st.session_state.rag_system.answer_question(user_input)
                
                answer = response.get("answer", "")
                sources = response.get("sources", [])
                
                # ì±—ë´‡ ì‘ë‹µ ì¶”ê°€
                st.session_state.chat_history.append({
                    "role": "assistant", 
                    "content": answer,
                    "sources": sources
                })
                
                # í™”ë©´ ê°±ì‹ 
                st.rerun()
                
            except Exception as e:
                # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€í•˜ê³  ë¬´í•œ ë£¨í”„ ë°©ì§€
                error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                st.session_state.chat_history.append({
                    "role": "assistant", 
                    "content": error_msg,
                    "sources": []
                })
                st.error(error_msg)

# ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸° ë²„íŠ¼
if st.session_state.chat_history and st.button("ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸°"):
    st.session_state.chat_history = []
    st.rerun() 