"""
Streamlitì„ ì´ìš©í•œ ê¸ˆìœµê°ë…ì› ì œì¬/ê²½ì˜ìœ ì˜ì‚¬í•­ RAG ì‹œìŠ¤í…œ ì›¹ ì¸í„°í˜ì´ìŠ¤
- ë²¡í„° ì €ì¥ì†Œ ê¸°ë°˜ RAG ì‹œìŠ¤í…œ ì—°ê²°
- ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ì œê³µ
- ê²€ìƒ‰ ê²°ê³¼ ì‹œê°í™”
"""

import os
import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import json
import time
from typing import Dict, List, Any, Union
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# RAG ì‹œìŠ¤í…œ ê°€ì ¸ì˜¤ê¸°
from rag_system import FSSRagSystem

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê¸ˆìœµê°ë…ì› ì œì¬ì •ë³´ ì±—ë´‡",
    page_icon="ğŸ’¼",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ìŠ¤íƒ€ì¼ ì¶”ê°€
st.markdown("""
<style>
.main-header {
    font-size: 2.5rem;
    color: #1E3A8A;
}
.sub-header {
    font-size: 1.5rem;
    color: #3B82F6;
}
.source-card {
    background-color: #F3F4F6;
    border-left: 4px solid #3B82F6;
    padding: 1rem;
    margin-bottom: 1rem;
    border-radius: 0.5rem;
}
.source-title {
    font-weight: bold;
    color: #1E3A8A;
}
.chat-message {
    padding: 1.5rem;
    border-radius: 0.5rem;
    margin-bottom: 1rem;
    display: flex;
    font-size: 1.1rem;
    line-height: 1.5;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
}
.user-message {
    background-color: #E0F2FE;
    margin-left: 2rem;
    border-left: 4px solid #0EA5E9;
    font-weight: 500;
}
.bot-message {
    background-color: #F0FDF4;
    margin-right: 2rem;
    border-left: 4px solid #10B981;
    font-weight: 500;
}
.message-content {
    font-size: 1.1rem;
    color: #111827;
}
.message-role {
    font-weight: bold;
    margin-right: 0.5rem;
    color: #1F2937;
}
.system-message {
    background-color: #FEF3C7;
    margin: 1rem 0;
    padding: 0.75rem;
    border-radius: 0.5rem;
    border-left: 4px solid #F59E0B;
    font-weight: 500;
}
</style>
""", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "rag_system" not in st.session_state:
    st.session_state.rag_system = None
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "vector_db_path" not in st.session_state:
    st.session_state.vector_db_path = "./data/vector_db/fss_sanctions"
if "embed_model" not in st.session_state:
    st.session_state.embed_model = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
if "use_openai_embeddings" not in st.session_state:
    st.session_state.use_openai_embeddings = True  # ê¸°ë³¸ê°’ì„ Trueë¡œ ë³€ê²½
if "llm_model" not in st.session_state:
    st.session_state.llm_model = "gpt-3.5-turbo"  # OpenAI ëª¨ë¸ë¡œ ë³€ê²½
if "top_k" not in st.session_state:
    st.session_state.top_k = 5
if "use_anthropic" not in st.session_state:
    st.session_state.use_anthropic = False  # ê¸°ë³¸ê°’ì„ Falseë¡œ ì„¤ì •
if "use_faiss" not in st.session_state:
    st.session_state.use_faiss = True  # FAISS ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’ True)
if "use_openai_llm" not in st.session_state:
    st.session_state.use_openai_llm = True  # OpenAI LLM ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’ True)
if "vector_store_loaded" not in st.session_state:
    st.session_state.vector_store_loaded = False

# ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ í•¨ìˆ˜ (ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰)
def load_vector_store():
    if not st.session_state.vector_store_loaded:
        with st.spinner("ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì¤‘..."):
            try:
                # ë²¡í„° ì €ì¥ì†Œë§Œ ë¡œë“œí•˜ëŠ” RAG ì‹œìŠ¤í…œ ìƒì„±
                st.session_state.rag_system = FSSRagSystem(
                    vector_db_path=st.session_state.vector_db_path,
                    embed_model_name=st.session_state.embed_model,
                    use_openai_embeddings=st.session_state.use_openai_embeddings,
                    use_anthropic=False,  # í•­ìƒ Falseë¡œ ì„¤ì • (LLMì€ ë³„ë„ë¡œ ì´ˆê¸°í™”)
                    use_faiss=st.session_state.use_faiss  # FAISS ì‚¬ìš© ì—¬ë¶€
                )
                
                # ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì„±ê³µ ì—¬ë¶€ í™•ì¸
                if st.session_state.rag_system.vector_store:
                    st.session_state.vector_store_loaded = True
                    return True
                else:
                    st.sidebar.error("ë²¡í„° ì €ì¥ì†Œ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    st.session_state.vector_store_loaded = False
                    return False
            except Exception as e:
                st.sidebar.error(f"ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                st.session_state.vector_store_loaded = False
                return False
    return True

# ì‚¬ì´ë“œë°”ì— RAG ì‹œìŠ¤í…œ ì„¤ì •
with st.sidebar:
    st.markdown("### ì‹œìŠ¤í…œ ì„¤ì •")
    
    # ë²¡í„° ì €ì¥ì†Œ ì„ íƒ
    vector_db_options = {
        "ì œì¬ ì •ë³´": "./data/vector_db/fss_sanctions",
        "ê²½ì˜ìœ ì˜ì‚¬í•­": "./data/vector_db/fss_management",
    }
    
    vector_db = st.selectbox(
        "ë²¡í„° ì €ì¥ì†Œ ì„ íƒ",
        options=list(vector_db_options.keys()),
        index=0,
        key="vector_db_selector"
    )
    
    # ë²¡í„° ì €ì¥ì†Œ ê²½ë¡œê°€ ë³€ê²½ëœ ê²½ìš° ì¬ë¡œë“œ í•„ìš”
    if st.session_state.vector_db_path != vector_db_options[vector_db]:
        st.session_state.vector_db_path = vector_db_options[vector_db]
        st.session_state.vector_store_loaded = False
    
    # ì„ë² ë”© ì„¤ì •
    st.markdown("### ì„ë² ë”© ì„¤ì •")

    # OpenAI ì„ë² ë”© ì‚¬ìš© ì—¬ë¶€ í™œì„±í™”
    use_openai = st.checkbox("OpenAI ì„ë² ë”© API ì‚¬ìš©", value=st.session_state.use_openai_embeddings)

    if use_openai != st.session_state.use_openai_embeddings:
        st.session_state.use_openai_embeddings = use_openai
        st.session_state.vector_store_loaded = False  # ì„ë² ë”© ëª¨ë¸ì´ ë³€ê²½ë˜ì–´ ì¬ë¡œë“œ í•„ìš”

    # OpenAI API í‚¤ í™•ì¸
    if st.session_state.use_openai_embeddings:
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if openai_api_key:
            st.success("âœ… OpenAI API í‚¤ê°€ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.error("âŒ í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.info("OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ HuggingFace ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì„¸ìš”.")

    # ë²¡í„° ì €ì¥ì†Œ íƒ€ì… ì„ íƒ
    vector_store_type = st.radio(
        "ë²¡í„° ì €ì¥ì†Œ íƒ€ì…",
        ["FAISS", "Chroma"],
        index=0 if st.session_state.use_faiss else 1
    )

    use_faiss = (vector_store_type == "FAISS")
    if use_faiss != st.session_state.use_faiss:
        st.session_state.use_faiss = use_faiss
        st.session_state.vector_store_loaded = False  # ë²¡í„° ì €ì¥ì†Œ íƒ€ì…ì´ ë³€ê²½ë˜ì–´ ì¬ë¡œë“œ í•„ìš”

    # HuggingFace ì„ë² ë”© ëª¨ë¸ ì„ íƒ (OpenAIë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì„ ê²½ìš°ì—ë§Œ í‘œì‹œ)
    if not st.session_state.use_openai_embeddings:
        embed_model_options = {
            "MiniLM-L12-v2 (ë‹¤êµ­ì–´)": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            "BGE-Large-Ko": "BAAI/bge-large-ko-v1.5",
        }

        embed_model = st.selectbox(
            "ì„ë² ë”© ëª¨ë¸",
            options=list(embed_model_options.keys()),
            index=0,
        )

        # ì„ë² ë”© ëª¨ë¸ì´ ë³€ê²½ëœ ê²½ìš° ì¬ë¡œë“œ í•„ìš”
        if st.session_state.embed_model != embed_model_options[embed_model]:
            st.session_state.embed_model = embed_model_options[embed_model]
            st.session_state.vector_store_loaded = False
    
    # ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ë²„íŠ¼
    if not st.session_state.vector_store_loaded:
        if st.button("ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ", type="primary"):
            if load_vector_store():
                st.sidebar.success("âœ… ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì™„ë£Œ")
    else:
        st.success("âœ… ë²¡í„° ì €ì¥ì†Œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤")
    
    st.markdown("---")
    
    # LLM ì„ íƒ - Anthropic API ë˜ëŠ” OpenAI API
    st.markdown("### LLM ì„¤ì •")

    llm_provider = st.radio(
        "LLM ì œê³µì",
        ["OpenAI", "Anthropic"],
        index=0 if not st.session_state.use_anthropic else 1
    )

    st.session_state.use_anthropic = (llm_provider == "Anthropic")
    st.session_state.use_openai_llm = (llm_provider == "OpenAI")

    # OpenAI ëª¨ë¸ ì„ íƒ
    if st.session_state.use_openai_llm:
        openai_models = {
            "GPT-3.5 Turbo": "gpt-3.5-turbo",
            "GPT-4 Turbo": "gpt-4-turbo",
            "GPT-4o": "gpt-4o",
        }
        
        openai_model = st.selectbox(
            "OpenAI ëª¨ë¸",
            options=list(openai_models.keys()),
            index=0,
        )
        
        st.session_state.llm_model = openai_models[openai_model]
        
        # OpenAI API í‚¤ í™•ì¸
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if openai_api_key:
            st.success("âœ… OpenAI API í‚¤ê°€ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.error("âŒ í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # Anthropic API í‚¤ í™•ì¸ ë° í‘œì‹œ
    elif st.session_state.use_anthropic:
        anthropic_api_key = os.getenv("ANTHROPIC_APIKEY")
        if anthropic_api_key:
            st.success("âœ… Anthropic API í‚¤ê°€ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.error("âŒ í™˜ê²½ ë³€ìˆ˜ ANTHROPIC_APIKEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜
    # top_k = st.slider("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜", min_value=1, max_value=10, value=5)
    # st.session_state.top_k = top_k
    
    # LLM ì´ˆê¸°í™” ë²„íŠ¼
    if st.session_state.vector_store_loaded:
        if st.button("LLM ì´ˆê¸°í™”", type="primary"):
            with st.spinner("LLM ì´ˆê¸°í™” ì¤‘..."):
                try:
                    if st.session_state.use_anthropic:
                        anthropic_api_key = os.getenv("ANTHROPIC_APIKEY")
                        if not anthropic_api_key:
                            st.error("í™˜ê²½ ë³€ìˆ˜ ANTHROPIC_APIKEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            # ê¸°ì¡´ RAG ì‹œìŠ¤í…œì— LLM ì´ˆê¸°í™”
                            st.session_state.rag_system.use_anthropic = True
                            st.session_state.rag_system.anthropic_api_key = anthropic_api_key
                            st.session_state.rag_system.use_openai_llm = False
                            st.session_state.rag_system.use_faiss = st.session_state.use_faiss
                            st.session_state.rag_system.initialize_llm()
                            if st.session_state.rag_system.llm:
                                st.success("Anthropic Claude APIë¡œ LLM ì´ˆê¸°í™” ì™„ë£Œ!")
                            else:
                                st.error("LLM ì´ˆê¸°í™” ì‹¤íŒ¨. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    else:
                        # OpenAI API ì‚¬ìš©
                        openai_api_key = os.getenv("OPENAI_API_KEY")
                        if not openai_api_key:
                            st.error("í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            # ê¸°ì¡´ RAG ì‹œìŠ¤í…œì— LLM ì´ˆê¸°í™”
                            st.session_state.rag_system.use_anthropic = False
                            st.session_state.rag_system.use_openai_llm = True
                            st.session_state.rag_system.llm_model_name = st.session_state.llm_model
                            st.session_state.rag_system.use_faiss = st.session_state.use_faiss
                            st.session_state.rag_system.initialize_llm()
                            if st.session_state.rag_system.llm:
                                st.success(f"OpenAI {st.session_state.llm_model}ë¡œ LLM ì´ˆê¸°í™” ì™„ë£Œ!")
                            else:
                                st.error("LLM ì´ˆê¸°í™” ì‹¤íŒ¨. API í‚¤ë¥¼ í™•ì¸í•˜ê³  ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                except Exception as e:
                    st.error(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

    st.markdown("---")
    
    # ë¹ ë¥¸ ì§ˆë¬¸ ì˜ˆì‹œ
    st.markdown("### ì§ˆë¬¸ ì˜ˆì‹œ")
    example_questions = [
        "ìµœê·¼ 1ë…„ê°„ ì œì¬ë°›ì€ ì€í–‰ ì•Œë ¤ì¤˜",
        "ì‹ ìš©ì •ë³´ë²• ìœ„ë°˜ ì‚¬ë¡€ ìˆì–´?",
        "ì£¼ì˜ ì¡°ì¹˜ ë°›ì€ ê¸ˆìœµì‚¬ ì¤‘ ë‚´ë¶€í†µì œ ë¬¸ì œì˜€ë˜ ê²½ìš°?",
        "ê³¼ì§•ê¸ˆ ë¶€ê³¼ëœ ë³´í—˜ì‚¬ ì•Œë ¤ì¤˜",
        "ì „ìê¸ˆìœµ ê´€ë ¨ ê²½ì˜ìœ ì˜ì‚¬í•­ì€?"
    ]
    
    # ì˜ˆì‹œ ì§ˆë¬¸ì„ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜
    def set_example_question(question):
        # ë™ì¼í•œ ì§ˆë¬¸ì´ ì´ë¯¸ ë§ˆì§€ë§‰ìœ¼ë¡œ ì…ë ¥ëœ ê²½ìš° ì¤‘ë³µ ë°©ì§€
        if st.session_state.chat_history and len(st.session_state.chat_history) > 0:
            last_user_msg = None
            for msg in reversed(st.session_state.chat_history):
                if msg["role"] == "user":
                    last_user_msg = msg["content"]
                    break
            
            if last_user_msg == question:
                # ì´ë¯¸ ë™ì¼í•œ ì§ˆë¬¸ì´ ì¡´ì¬í•˜ë©´ ë‹¤ì‹œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
                return
        
        st.session_state.chat_input = question
        st.rerun()
    
    for q in example_questions:
        if st.sidebar.button(q):
            set_example_question(q)

# ë©”ì¸ í™”ë©´
st.markdown('<h1 class="main-header">ê¸ˆìœµê°ë…ì› ì œì¬ì •ë³´ ì±—ë´‡</h1>', unsafe_allow_html=True)
st.markdown('<h2 class="sub-header">ê¸ˆìœµ ì œì¬ ë° ê²½ì˜ìœ ì˜ì‚¬í•­ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ</h2>', unsafe_allow_html=True)

# ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
system_status_shown = False
if not st.session_state.vector_store_loaded:
    st.markdown('<div class="system-message">âš ï¸ ì‚¬ì´ë“œë°”ì—ì„œ ë²¡í„° ì €ì¥ì†Œë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”.</div>', unsafe_allow_html=True)
    system_status_shown = True
elif st.session_state.rag_system and not st.session_state.rag_system.llm:
    st.markdown('<div class="system-message">âš ï¸ ì‚¬ì´ë“œë°”ì—ì„œ LLMì„ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.</div>', unsafe_allow_html=True)
    system_status_shown = True

# ë²¡í„° ì €ì¥ì†Œ ìë™ ë¡œë“œ ì‹œë„ëŠ” ì œê±° (ì¤‘ë³µ ë©”ì‹œì§€ ë°©ì§€)

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for i, message in enumerate(st.session_state.chat_history):
    if message["role"] == "user":
        with st.container():
            st.markdown(f'<div class="chat-message user-message"><span class="message-role">ğŸ§‘â€ğŸ’¼</span><span class="message-content">{message["content"]}</span></div>', unsafe_allow_html=True)
    else:
        with st.container():
            st.markdown(f'<div class="chat-message bot-message"><span class="message-role">ğŸ¤–</span><span class="message-content">{message["content"]}</span></div>', unsafe_allow_html=True)
            
            if "sources" in message and message["sources"]:
                with st.expander("ì°¸ê³  ë¬¸ì„œ ë³´ê¸°"):
                    for j, source in enumerate(message["sources"][:3]):
                        metadata = source.get("metadata", {})
                        
                        # DB íƒ€ì…ì— ë”°ë¼ ë‚ ì§œì™€ ìœ í˜•ì„ ê²°ì •í•©ë‹ˆë‹¤.
                        date_to_display = metadata.get('sanction_date') or metadata.get('disclosure_date', 'N/A')
                        type_to_display = metadata.get('sanction_type') or metadata.get('management_type', 'N/A')

                        st.markdown(f"""
                        <div class="source-card">
                            <p class="source-title">ì¶œì²˜ #{j+1}</p>
                            <p><strong>ê¸°ê´€:</strong> {metadata.get('institution', 'N/A')}</p>
                            <p><strong>ë‚ ì§œ:</strong> {date_to_display}</p>
                            <p><strong>ìœ í˜•:</strong> {type_to_display}</p>
                            <p>{source.get('content', '')[:300]}...</p>
                        </div>
                        """, unsafe_allow_html=True)

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...", key="chat_input")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    
    # ë²¡í„° ì €ì¥ì†Œì™€ LLM ìƒíƒœ í™•ì¸
    if not st.session_state.vector_store_loaded:
        error_msg = "ë²¡í„° ì €ì¥ì†Œê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ 'ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ' ë²„íŠ¼ì„ í´ë¦­í•´ì£¼ì„¸ìš”."
        st.session_state.chat_history.append({
            "role": "assistant", 
            "content": error_msg,
            "sources": []
        })
        st.error(error_msg)
        st.rerun()
    elif st.session_state.rag_system and not st.session_state.rag_system.llm:
        error_msg = "LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ 'LLM ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•´ì£¼ì„¸ìš”."
        st.session_state.chat_history.append({
            "role": "assistant", 
            "content": error_msg,
            "sources": []
        })
        st.error(error_msg)
        st.rerun()
    else:
        # ì‹œìŠ¤í…œ ì‘ë‹µ ìƒì„±
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                response = st.session_state.rag_system.answer_question(user_input)
                
                answer = response.get("answer", "")
                sources = response.get("sources", [])
                
                # ì±—ë´‡ ì‘ë‹µ ì¶”ê°€
                st.session_state.chat_history.append({
                    "role": "assistant", 
                    "content": answer,
                    "sources": sources
                })
                
                # í™”ë©´ ê°±ì‹ 
                st.rerun()
                
            except Exception as e:
                # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€í•˜ê³  ë¬´í•œ ë£¨í”„ ë°©ì§€
                error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                st.session_state.chat_history.append({
                    "role": "assistant", 
                    "content": error_msg,
                    "sources": []
                })
                st.error(error_msg)

# ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸° ë²„íŠ¼
if st.session_state.chat_history and st.button("ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸°"):
    st.session_state.chat_history = []
    st.rerun() 