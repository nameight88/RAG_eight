"""
ê¸ˆìœµê°ë…ì› ì œì¬/ê²½ì˜ìœ ì˜ì‚¬í•­ RAG íŒŒì´í”„ë¼ì¸
- ì½”í¼ìŠ¤ ë¡œë“œ ë° ì²­í‚¹
- ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•
- ëŒ€í™”í˜• RAG ì‹œìŠ¤í…œ ì‹¤í–‰
"""

import os
import argparse
import json
from typing import Dict, List, Any, Optional
import shutil
from datetime import datetime
from dotenv import load_dotenv
from semantic_chunker import FSSSemanticChunker
from adaptive_chunker import FSSAdaptiveChunker
from rag_system import FSSRagSystem

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


def parse_arguments():
    """ëª…ë ¹í–‰ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(description='ê¸ˆìœµê°ë…ì› ì œì¬/ê²½ì˜ìœ ì˜ì‚¬í•­ RAG íŒŒì´í”„ë¼ì¸')
    
    # ì…ë ¥ íŒŒì¼/ë””ë ‰í† ë¦¬ ì„¤ì •
    parser.add_argument('--sanctions-json', type=str, default='./data/fss_sanctions_parsed.json',
                        help='ì œì¬ ì •ë³´ íŒŒì‹±ëœ JSON íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--management-json', type=str, default='./data/fss_management_parsed.json',
                        help='ê²½ì˜ìœ ì˜ì‚¬í•­ íŒŒì‹±ëœ JSON íŒŒì¼ ê²½ë¡œ')
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    parser.add_argument('--vector-db-dir', type=str, default='./data/vector_db',
                        help='ë²¡í„° ì €ì¥ì†Œ ë””ë ‰í† ë¦¬')
    
    # ì„ë² ë”© ì„¤ì •
    parser.add_argument('--embed-model', type=str, 
                        default='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
                        help='ì„ë² ë”© ëª¨ë¸ ì´ë¦„')
    parser.add_argument('--use-openai-embeddings', action='store_true', default=True,
                        help='OpenAI ì„ë² ë”© API ì‚¬ìš© (í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEY í•„ìš”)')
    parser.add_argument('--use-faiss', action='store_true', default=True,
                        help='Chroma ëŒ€ì‹  FAISS ë²¡í„° ì €ì¥ì†Œ ì‚¬ìš©')
    
    # ì²­í‚¹ ì„¤ì •
    parser.add_argument('--chunk-size', type=int, default=512,
                        help='ì²­í¬ í¬ê¸°')
    parser.add_argument('--chunk-overlap', type=int, default=50,
                        help='ì²­í¬ ê²¹ì¹¨ í¬ê¸°')
    
    # ì²˜ë¦¬ ë‹¨ê³„ ì„ íƒ
    parser.add_argument('--skip-sanctions', action='store_true',
                        help='ì œì¬ ì •ë³´ ì²˜ë¦¬ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-management', action='store_true',
                        help='ê²½ì˜ìœ ì˜ì‚¬í•­ ì²˜ë¦¬ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--interactive', action='store_true',
                        help='ì²˜ë¦¬ í›„ ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰')
    
    return parser.parse_args()


def process_sanctions(args):
    """ì œì¬ ì •ë³´ ì²˜ë¦¬"""
    print("\nğŸ”„ ì œì¬ ì •ë³´ ì²˜ë¦¬ ì‹œì‘...")
    
    # ë””ë ‰í† ë¦¬ ì„¤ì •
    sanctions_db_dir = os.path.join(os.path.abspath(args.vector_db_dir), "fss_sanctions")
    os.makedirs(sanctions_db_dir, exist_ok=True)
    
    # ì‹œë§¨í‹± ì²­ì»¤ ì´ˆê¸°í™” ë° ì²˜ë¦¬
    sanctions_chunker = FSSSemanticChunker(
        input_json=os.path.abspath(args.sanctions_json),
        output_dir=sanctions_db_dir,
        model_name=args.embed_model,
        use_openai_embeddings=args.use_openai_embeddings,
        chunk_size=args.chunk_size,
        chunk_overlap=args.chunk_overlap,
        use_faiss=args.use_faiss  # FAISS ì‚¬ìš© ì—¬ë¶€ ì¶”ê°€
    )
    
    sanctions_chunker.process()
    
    print("âœ… ì œì¬ ì •ë³´ ì²˜ë¦¬ ì™„ë£Œ")


def process_management(args):
    """ê²½ì˜ìœ ì˜ì‚¬í•­ ì²˜ë¦¬"""
    print("\nğŸ”„ ê²½ì˜ìœ ì˜ì‚¬í•­ ì²˜ë¦¬ ì‹œì‘...")
    
    # ë””ë ‰í† ë¦¬ ì„¤ì •
    management_db_dir = os.path.join(os.path.abspath(args.vector_db_dir), "fss_management")
    os.makedirs(management_db_dir, exist_ok=True)
    
    # ì ì‘í˜• ì²­ì»¤ ì´ˆê¸°í™” ë° ì²˜ë¦¬
    management_chunker = FSSAdaptiveChunker(
        input_json=os.path.abspath(args.management_json),
        output_dir=management_db_dir,
        model_name=args.embed_model,
        use_openai_embeddings=args.use_openai_embeddings,
        default_chunk_size=args.chunk_size,
        default_chunk_overlap=args.chunk_overlap,
        use_faiss=args.use_faiss  # FAISS ì‚¬ìš© ì—¬ë¶€ ì¶”ê°€
    )
    
    management_chunker.process()
    
    print("âœ… ê²½ì˜ìœ ì˜ì‚¬í•­ ì²˜ë¦¬ ì™„ë£Œ")


def run_interactive_mode(args):
    """ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰"""
    print("\nğŸ¤– ëŒ€í™”í˜• ëª¨ë“œ ì‹œì‘...")
    
    # DB ìœ í˜• ì„ íƒ
    print("\nì‚¬ìš©í•  ë²¡í„° ì €ì¥ì†Œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ì œì¬ ì •ë³´")
    print("2. ê²½ì˜ìœ ì˜ì‚¬í•­")
    choice = input("ì„ íƒ (ê¸°ë³¸ê°’: 1): ").strip() or "1"
    
    if choice == "2":
        db_path = os.path.join(os.path.abspath(args.vector_db_dir), "fss_management")
        print("ê²½ì˜ìœ ì˜ì‚¬í•­ ë²¡í„° ì €ì¥ì†Œ ì‚¬ìš©")
    else:
        db_path = os.path.join(os.path.abspath(args.vector_db_dir), "fss_sanctions")
        print("ì œì¬ ì •ë³´ ë²¡í„° ì €ì¥ì†Œ ì‚¬ìš©")
    
    # API ì„ íƒ
    print("\nì‚¬ìš©í•  LLM APIë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. OpenAI API (ê¸°ë³¸ê°’)")
    print("2. Anthropic Claude API")
    api_choice = input("ì„ íƒ (ê¸°ë³¸ê°’: 1): ").strip() or "1"
    
    use_anthropic = (api_choice == "2")
    use_openai = (api_choice == "1")
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if use_anthropic:
        anthropic_api_key = os.getenv("ANTHROPIC_APIKEY")
        if not anthropic_api_key:
            anthropic_api_key = input("Anthropic API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
        
        rag_system = FSSRagSystem(
            vector_db_path=db_path,
            embed_model_name=args.embed_model,
            use_openai_embeddings=args.use_openai_embeddings,
            use_anthropic=True,
            anthropic_api_key=anthropic_api_key,
            top_k=5,
            use_faiss=args.use_faiss,  # FAISS ì‚¬ìš© ì—¬ë¶€ ì¶”ê°€
            use_openai_llm=False
        )
    else:  # OpenAI API ì‚¬ìš© (ê¸°ë³¸ê°’)
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            print("âš ï¸ í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        rag_system = FSSRagSystem(
            vector_db_path=db_path,
            embed_model_name=args.embed_model,
            use_openai_embeddings=args.use_openai_embeddings,
            llm_model_name="gpt-3.5-turbo",  # OpenAI ëª¨ë¸ ì‚¬ìš©
            top_k=5,
            use_faiss=args.use_faiss,  # FAISS ì‚¬ìš© ì—¬ë¶€ ì¶”ê°€
            use_openai_llm=True  # OpenAI LLM ì‚¬ìš©
        )
    
    # ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰
    rag_system.interactive_mode()


def create_vector_stores(args):
    """ë²¡í„° ì €ì¥ì†Œ ìƒì„± ë° ì €ì¥"""
    print("\nğŸ”„ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì‹œì‘...")
    
    # OpenAI API í‚¤ í™•ì¸
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        print("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    try:
        # ì œì¬ ì •ë³´ ë²¡í„° ì €ì¥ì†Œ ìƒì„±
        if not args.skip_sanctions:
            sanctions_dir = os.path.join(args.vector_db_dir, "fss_sanctions")
            os.makedirs(sanctions_dir, exist_ok=True)
            
            # RAG ì‹œìŠ¤í…œìœ¼ë¡œ ë²¡í„° ì €ì¥ì†Œ ìƒì„±
            from rag_system import FSSRagSystem
            sanctions_rag = FSSRagSystem(
                vector_db_path=sanctions_dir,
                embed_model_name=args.embed_model,
                use_openai_embeddings=args.use_openai_embeddings,
                use_anthropic=False,
                use_faiss=args.use_faiss,
                create_from_json=args.sanctions_json
            )
            
            if not sanctions_rag.vector_store:
                print("âŒ ì œì¬ ì •ë³´ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì‹¤íŒ¨")
                return False
            
            # ë²¡í„° ì €ì¥ì†Œ ì •ë³´ ì €ì¥
            info_path = os.path.join(sanctions_dir, "vector_store_info.json")
            info = {
                "created_at": datetime.now().isoformat(),
                "embed_model": "text-embedding-3-large" if args.use_openai_embeddings else args.embed_model,
                "use_openai": args.use_openai_embeddings,
                "vector_store_type": "FAISS" if args.use_faiss else "Chroma"
            }
            with open(info_path, 'w', encoding='utf-8') as f:
                json.dump(info, f, ensure_ascii=False, indent=2)
            
            print("âœ… ì œì¬ ì •ë³´ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ")
        
        # ê²½ì˜ìœ ì˜ì‚¬í•­ ë²¡í„° ì €ì¥ì†Œ ìƒì„±
        if not args.skip_management:
            management_dir = os.path.join(args.vector_db_dir, "fss_management")
            os.makedirs(management_dir, exist_ok=True)
            
            # RAG ì‹œìŠ¤í…œìœ¼ë¡œ ë²¡í„° ì €ì¥ì†Œ ìƒì„±
            from rag_system import FSSRagSystem
            management_rag = FSSRagSystem(
                vector_db_path=management_dir,
                embed_model_name=args.embed_model,
                use_openai_embeddings=args.use_openai_embeddings,
                use_anthropic=False,
                use_faiss=args.use_faiss,
                create_from_json=args.management_json
            )
            
            if not management_rag.vector_store:
                print("âŒ ê²½ì˜ìœ ì˜ì‚¬í•­ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì‹¤íŒ¨")
                return False
            
            # ë²¡í„° ì €ì¥ì†Œ ì •ë³´ ì €ì¥
            info_path = os.path.join(management_dir, "vector_store_info.json")
            info = {
                "created_at": datetime.now().isoformat(),
                "embed_model": "text-embedding-3-large" if args.use_openai_embeddings else args.embed_model,
                "use_openai": args.use_openai_embeddings,
                "vector_store_type": "FAISS" if args.use_faiss else "Chroma"
            }
            with open(info_path, 'w', encoding='utf-8') as f:
                json.dump(info, f, ensure_ascii=False, indent=2)
            
            print("âœ… ê²½ì˜ìœ ì˜ì‚¬í•­ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ")
        
        print("\nğŸ‰ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ!")
        print("ìƒì„±ëœ ë²¡í„° ì €ì¥ì†Œë¥¼ GitHubì— ì»¤ë°‹í•˜ì„¸ìš”.")
        return True
        
    except Exception as e:
        print(f"âŒ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ê¸ˆìœµê°ë…ì› ì œì¬/ê²½ì˜ìœ ì˜ì‚¬í•­ RAG íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    
    # ì¸ì íŒŒì‹±
    args = parse_arguments()
    
    # ê²½ë¡œ ì •ê·œí™”
    args.sanctions_json = os.path.abspath(args.sanctions_json)
    args.management_json = os.path.abspath(args.management_json)
    args.vector_db_dir = os.path.abspath(args.vector_db_dir)
    
    # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(os.path.dirname(args.sanctions_json), exist_ok=True)
    os.makedirs(os.path.dirname(args.management_json), exist_ok=True)
    os.makedirs(args.vector_db_dir, exist_ok=True)
    
    # OpenAI API í‚¤ í™•ì¸
    if args.use_openai_embeddings:
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            print("âš ï¸ í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("OpenAI ì„ë² ë”©ì„ ì‚¬ìš©í•˜ë ¤ë©´ .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            print("HuggingFace ì„ë² ë”©ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            args.use_openai_embeddings = False
    
    
    # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
    create_vector_stores(args)
    
    # ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰
    if args.interactive:
        run_interactive_mode(args)
    
    print("\nğŸ‰ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 